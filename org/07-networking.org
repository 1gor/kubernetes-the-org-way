# -*- mode: org; mode: auto-fill -*-
#+TITLE: Networking The Org Way

*** Notes

#+BEGIN_QUOTE
Now that each worker node is online we need to add routes to make sure
that Pods running on different machines can talk to each other. In
this lab we are not going to provision any overlay networks and
instead rely on Layer 3 networking. That means we need to add routes
to our router. In GCP each network has a router that can be
configured. If this was an on-prem datacenter then ideally you would
need to add the routes to your local router.
#+END_QUOTE

*** Container Subnets

#+BEGIN_QUOTE
The IP addresses for each pod will be allocated from the =podCIDR= range
assinged to each Kubernetes worker through the node registration
process.
#+END_QUOTE

***** =podCIDR=

#+BEGIN_QUOTE
During the worker setup process the following flags were set on the
Kubelet to ensure each node obtained a =podCIDR= from the API server:
#+END_QUOTE

#+BEGIN_SRC sh
--configure-cbr0=true
--reconcile-cidr=true
#+END_SRC

#+BEGIN_QUOTE
The =podCIDR= will be allocated from the cluster cidr range as
configured on the Kubernetes Controller Manager with the following
flag:
#+END_QUOTE

#+BEGIN_SRC 
--cluster-cidr=10.200.0.0/16
#+END_SRC

#+BEGIN_QUOTE
Based on the above configuration each node will receive a =/24=
subnet. For example:
#+END_QUOTE

#+BEGIN_SRC 
10.200.0.0/24
10.200.1.0/24
10.200.2.0/24
...
#+END_SRC

**** Get the Routing Table

#+BEGIN_QUOTE
The first thing we need to do is gather the information required to
populate the router table. We need the Internal IP address and Pod
Subnet for each of the worker nodes.
#+END_QUOTE

Use kubectl to print the =InternalIP= and =podCIDR= for each worker node:

#+BEGIN_SRC sh :results output code :exports both
kubectl get nodes \
  --output=jsonpath='{range .items[*]}{.status.addresses[?(@.type=="InternalIP")].address} {.spec.podCIDR} {"\n"}{end}'
#+END_SRC

#+RESULTS:
#+BEGIN_SRC sh
10.240.0.30 10.200.0.0/24 
#+END_SRC

#+BEGIN_SRC sh :results output code
kubectl get nodes \
  --output=jsonpath='
| Internal IP | podCIDR |
{range .items[*]}| {.status.addresses[?(@.type=="InternalIP")].address} | {.spec.podCIDR} | {"\n"}
{end}'
#+END_SRC

| Internal IP | podCIDR       |
| 10.240.0.30 | 10.200.0.0/24 |

#+END_SRC

**** Create Routes

#+BEGIN_SRC sh :results output :exports both
gcloud compute routes create kubernetes-route-10-200-0-0-24 \
  --network kubernetes \
  --next-hop-address 10.240.0.30 \
  --destination-range 10.200.0.0/24
#+END_SRC

#+RESULTS:
: NAME                            NETWORK     DEST_RANGE     NEXT_HOP     PRIORITY
: kubernetes-route-10-200-0-0-24  kubernetes  10.200.0.0/24  10.240.0.30  1000

#+BEGIN_SRC sh :results output :exports both
gcloud compute routes create kubernetes-route-10-200-1-0-24 \
  --network kubernetes \
  --next-hop-address 10.240.0.31 \
  --destination-range 10.200.1.0/24
#+END_SRC

#+RESULTS:
: NAME                            NETWORK     DEST_RANGE     NEXT_HOP     PRIORITY
: kubernetes-route-10-200-1-0-24  kubernetes  10.200.1.0/24  10.240.0.31  1000

#+BEGIN_SRC sh :results output :exports both
gcloud compute routes create kubernetes-route-10-200-2-0-24 \
  --network kubernetes \
  --next-hop-address 10.240.0.32 \
  --destination-range 10.200.2.0/24
#+END_SRC

#+RESULTS:
: NAME                            NETWORK     DEST_RANGE     NEXT_HOP     PRIORITY
: kubernetes-route-10-200-2-0-24  kubernetes  10.200.2.0/24  10.240.0.32  1000

